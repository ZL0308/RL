{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80df0846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from DQN import DQN\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724dfa48",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(                          ## initialize the enverionment \n",
    "    \"LunarLander-v2\",\n",
    "    continuous=False,\n",
    "    gravity=-10.0,\n",
    "    enable_wind=False,\n",
    "    wind_power=15.0,\n",
    "    turbulence_power=1.5,\n",
    "    render_mode=\"human\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7e72bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DQN(\n",
       "  (fc1): Linear(in_features=8, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net = DQN(8, 4).to(\"cuda\")\n",
    "#policy_net.load_state_dict(torch.load('policy_net_model.pth'))\n",
    "\n",
    "target_net = DQN(8, 4).to(\"cuda\")\n",
    "target_net.load_state_dict(policy_net.state_dict())          # initialize the weights and bias\n",
    "target_net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44211865",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(policy_net.parameters(), lr=0.0001, weight_decay=1e-5)\n",
    "replay_memory = []\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "max_steps = 900\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5220388a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zheng\\AppData\\Local\\Temp\\ipykernel_3284\\296936211.py:50: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  batch_states = torch.FloatTensor(batch_states).to(\"cuda\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Total Reward = -249.1593968860744, Average Loss = 1.9183, Epsilon: 0.995\n",
      "Episode 1: Total Reward = -101.90055885614142, Average Loss = 76.1729, Epsilon: 0.990025\n",
      "Episode 2: Total Reward = -92.36726627956331, Average Loss = 82.9125, Epsilon: 0.985074875\n",
      "Episode 3: Total Reward = -177.6413030335481, Average Loss = 86.7783, Epsilon: 0.9801495006250001\n",
      "Episode 4: Total Reward = -90.33425445018669, Average Loss = 84.4105, Epsilon: 0.9752487531218751\n",
      "Episode 5: Total Reward = -78.30168748069141, Average Loss = 108.3332, Epsilon: 0.9703725093562657\n",
      "Episode 6: Total Reward = -411.57120090564933, Average Loss = 89.2919, Epsilon: 0.9655206468094844\n",
      "Episode 7: Total Reward = -420.4554483686753, Average Loss = 92.6828, Epsilon: 0.960693043575437\n",
      "Episode 8: Total Reward = -108.62154511326364, Average Loss = 82.3597, Epsilon: 0.9558895783575597\n",
      "Episode 9: Total Reward = -306.6493789030952, Average Loss = 99.9629, Epsilon: 0.9511101304657719\n",
      "Episode 10: Total Reward = -230.6528221530052, Average Loss = 87.4576, Epsilon: 0.946354579813443\n",
      "Episode 11: Total Reward = -419.3810911714774, Average Loss = 85.1667, Epsilon: 0.9416228069143757\n",
      "Episode 12: Total Reward = -399.48235881457776, Average Loss = 93.2935, Epsilon: 0.9369146928798039\n",
      "Episode 13: Total Reward = -364.45955936056646, Average Loss = 78.3856, Epsilon: 0.9322301194154049\n",
      "Episode 14: Total Reward = -164.97209646249723, Average Loss = 73.5882, Epsilon: 0.9275689688183278\n",
      "Episode 15: Total Reward = -74.7697448292639, Average Loss = 94.5514, Epsilon: 0.9229311239742362\n",
      "Episode 16: Total Reward = -294.325106742846, Average Loss = 77.9067, Epsilon: 0.918316468354365\n",
      "Episode 17: Total Reward = -67.12709533538874, Average Loss = 60.4256, Epsilon: 0.9137248860125932\n",
      "Episode 18: Total Reward = -236.72524554302015, Average Loss = 59.4419, Epsilon: 0.9091562615825302\n",
      "Episode 19: Total Reward = -268.42519317518315, Average Loss = 58.3796, Epsilon: 0.9046104802746175\n",
      "Episode 20: Total Reward = -196.58146210893895, Average Loss = 44.6894, Epsilon: 0.9000874278732445\n",
      "Episode 21: Total Reward = -132.70794456147502, Average Loss = 55.6034, Epsilon: 0.8955869907338783\n",
      "Episode 22: Total Reward = -165.26857130009182, Average Loss = 61.9405, Epsilon: 0.8911090557802088\n",
      "Episode 23: Total Reward = -264.00378730898484, Average Loss = 55.2819, Epsilon: 0.8866535105013078\n",
      "Episode 24: Total Reward = -123.17740336848476, Average Loss = 60.7035, Epsilon: 0.8822202429488013\n",
      "Episode 25: Total Reward = -67.73684447641105, Average Loss = 54.3471, Epsilon: 0.8778091417340573\n",
      "Episode 26: Total Reward = -5.194550539934696, Average Loss = 58.9907, Epsilon: 0.8734200960253871\n",
      "Episode 27: Total Reward = -118.6514718381341, Average Loss = 75.3301, Epsilon: 0.8690529955452602\n",
      "Episode 28: Total Reward = -115.39819163539585, Average Loss = 58.1230, Epsilon: 0.8647077305675338\n",
      "Episode 29: Total Reward = -370.5416007522516, Average Loss = 65.5879, Epsilon: 0.8603841919146962\n",
      "Episode 30: Total Reward = -313.5543378207659, Average Loss = 52.8744, Epsilon: 0.8560822709551227\n",
      "Episode 31: Total Reward = -221.428505557014, Average Loss = 43.0793, Epsilon: 0.851801859600347\n",
      "Episode 32: Total Reward = -139.38966715683313, Average Loss = 42.0550, Epsilon: 0.8475428503023453\n",
      "Episode 33: Total Reward = -179.83713167610216, Average Loss = 49.3505, Epsilon: 0.8433051360508336\n",
      "Episode 34: Total Reward = -54.13426338896804, Average Loss = 44.2838, Epsilon: 0.8390886103705794\n",
      "Episode 35: Total Reward = -51.805285400942125, Average Loss = 44.7006, Epsilon: 0.8348931673187264\n",
      "Episode 36: Total Reward = -380.9121462407014, Average Loss = 40.3536, Epsilon: 0.8307187014821328\n",
      "Episode 37: Total Reward = -211.22217601189254, Average Loss = 48.0379, Epsilon: 0.8265651079747222\n",
      "Episode 38: Total Reward = -139.16137571928692, Average Loss = 36.3909, Epsilon: 0.8224322824348486\n",
      "Episode 39: Total Reward = -233.9905244139605, Average Loss = 39.4798, Epsilon: 0.8183201210226743\n",
      "Episode 40: Total Reward = -155.13971294863333, Average Loss = 32.6261, Epsilon: 0.8142285204175609\n",
      "Episode 41: Total Reward = -261.6837093588881, Average Loss = 39.3207, Epsilon: 0.810157377815473\n",
      "Episode 42: Total Reward = -11.969620142884892, Average Loss = 34.1964, Epsilon: 0.8061065909263957\n",
      "Episode 43: Total Reward = -225.35172960547584, Average Loss = 38.6118, Epsilon: 0.8020760579717637\n",
      "Episode 44: Total Reward = -51.11122410019716, Average Loss = 36.7596, Epsilon: 0.798065677681905\n",
      "Episode 45: Total Reward = -253.0704713548401, Average Loss = 43.6983, Epsilon: 0.7940753492934954\n",
      "Episode 46: Total Reward = -135.95366355399022, Average Loss = 39.8883, Epsilon: 0.7901049725470279\n",
      "Episode 47: Total Reward = -128.42229197637394, Average Loss = 26.1852, Epsilon: 0.7861544476842928\n",
      "Episode 48: Total Reward = -96.74296170915206, Average Loss = 31.5645, Epsilon: 0.7822236754458713\n",
      "Episode 49: Total Reward = -83.42552089935346, Average Loss = 26.3501, Epsilon: 0.778312557068642\n",
      "Episode 50: Total Reward = -428.67646230607403, Average Loss = 24.6167, Epsilon: 0.7744209942832988\n",
      "Episode 51: Total Reward = -123.36582040917321, Average Loss = 27.6716, Epsilon: 0.7705488893118823\n",
      "Episode 52: Total Reward = -87.39060834982159, Average Loss = 22.5000, Epsilon: 0.7666961448653229\n",
      "Episode 53: Total Reward = -136.13037598755756, Average Loss = 35.0465, Epsilon: 0.7628626641409962\n",
      "Episode 54: Total Reward = -109.45095617325046, Average Loss = 22.5208, Epsilon: 0.7590483508202912\n",
      "Episode 55: Total Reward = -81.02813975931593, Average Loss = 35.3825, Epsilon: 0.7552531090661897\n",
      "Episode 56: Total Reward = -43.64612138928669, Average Loss = 28.2987, Epsilon: 0.7514768435208588\n",
      "Episode 57: Total Reward = -110.64398076135339, Average Loss = 26.1781, Epsilon: 0.7477194593032545\n",
      "Episode 58: Total Reward = -140.8132963743052, Average Loss = 25.9504, Epsilon: 0.7439808620067382\n",
      "Episode 59: Total Reward = -97.496701726907, Average Loss = 22.2109, Epsilon: 0.7402609576967045\n",
      "Episode 60: Total Reward = -234.03140475365615, Average Loss = 27.1568, Epsilon: 0.736559652908221\n",
      "Episode 61: Total Reward = -189.43412738563975, Average Loss = 23.2385, Epsilon: 0.7328768546436799\n",
      "Episode 62: Total Reward = -186.90970022066034, Average Loss = 31.5039, Epsilon: 0.7292124703704616\n",
      "Episode 63: Total Reward = -175.51946590722707, Average Loss = 27.2098, Epsilon: 0.7255664080186093\n",
      "Episode 64: Total Reward = -172.42683256101253, Average Loss = 30.7324, Epsilon: 0.7219385759785162\n",
      "Episode 65: Total Reward = -111.26577356082831, Average Loss = 27.5047, Epsilon: 0.7183288830986236\n",
      "Episode 66: Total Reward = -89.64986741657015, Average Loss = 24.8596, Epsilon: 0.7147372386831305\n",
      "Episode 67: Total Reward = -134.96037456777515, Average Loss = 19.9129, Epsilon: 0.7111635524897149\n",
      "Episode 68: Total Reward = -152.75530713010005, Average Loss = 27.2080, Epsilon: 0.7076077347272662\n",
      "Episode 69: Total Reward = -56.67810531407797, Average Loss = 25.8892, Epsilon: 0.7040696960536299\n",
      "Episode 70: Total Reward = -212.7520759934127, Average Loss = 28.9200, Epsilon: 0.7005493475733617\n",
      "Episode 71: Total Reward = -64.01898156111139, Average Loss = 25.7092, Epsilon: 0.697046600835495\n",
      "Episode 72: Total Reward = -55.64990515105532, Average Loss = 25.1701, Epsilon: 0.6935613678313175\n",
      "Episode 73: Total Reward = -71.75217260951413, Average Loss = 26.2637, Epsilon: 0.6900935609921609\n",
      "Episode 74: Total Reward = -29.08687306448313, Average Loss = 21.9355, Epsilon: 0.6866430931872001\n",
      "Episode 75: Total Reward = -174.1289311448078, Average Loss = 29.2727, Epsilon: 0.6832098777212641\n",
      "Episode 76: Total Reward = -121.68858140445994, Average Loss = 25.9853, Epsilon: 0.6797938283326578\n",
      "Episode 77: Total Reward = -90.65860282291048, Average Loss = 23.0135, Epsilon: 0.6763948591909945\n",
      "Episode 78: Total Reward = -110.96140913898448, Average Loss = 24.7771, Epsilon: 0.6730128848950395\n",
      "Episode 79: Total Reward = -382.4219118597441, Average Loss = 22.4518, Epsilon: 0.6696478204705644\n",
      "Episode 80: Total Reward = -81.66946100751113, Average Loss = 26.9333, Epsilon: 0.6662995813682115\n",
      "Episode 81: Total Reward = -90.96362369554583, Average Loss = 20.6039, Epsilon: 0.6629680834613705\n",
      "Episode 82: Total Reward = -94.5109862902473, Average Loss = 22.9584, Epsilon: 0.6596532430440636\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 83: Total Reward = -102.22994800896582, Average Loss = 23.0008, Epsilon: 0.6563549768288433\n",
      "Episode 84: Total Reward = -6.712249369789063, Average Loss = 20.2926, Epsilon: 0.653073201944699\n",
      "Episode 85: Total Reward = -122.12179738121755, Average Loss = 23.0822, Epsilon: 0.6498078359349755\n",
      "Episode 86: Total Reward = -466.74497017122314, Average Loss = 18.9262, Epsilon: 0.6465587967553006\n",
      "Episode 87: Total Reward = -110.32338127651877, Average Loss = 17.7297, Epsilon: 0.6433260027715241\n",
      "Episode 88: Total Reward = -36.94771726055634, Average Loss = 19.3767, Epsilon: 0.6401093727576664\n",
      "Episode 89: Total Reward = -37.419843785609366, Average Loss = 17.2382, Epsilon: 0.6369088258938781\n",
      "Episode 90: Total Reward = -299.631512736796, Average Loss = 20.8697, Epsilon: 0.6337242817644086\n",
      "Episode 91: Total Reward = -69.55287596315758, Average Loss = 20.5716, Epsilon: 0.6305556603555866\n",
      "Episode 92: Total Reward = -70.73080623684531, Average Loss = 22.0092, Epsilon: 0.6274028820538087\n",
      "Episode 93: Total Reward = -66.05692930128839, Average Loss = 21.7286, Epsilon: 0.6242658676435396\n",
      "Episode 94: Total Reward = -375.4269731129833, Average Loss = 18.9076, Epsilon: 0.6211445383053219\n",
      "Episode 95: Total Reward = -75.84415310498542, Average Loss = 18.9333, Epsilon: 0.6180388156137953\n",
      "Episode 96: Total Reward = -126.68293089105894, Average Loss = 19.0041, Epsilon: 0.6149486215357263\n",
      "Episode 97: Total Reward = -199.79017127171494, Average Loss = 19.6021, Epsilon: 0.6118738784280476\n",
      "Episode 98: Total Reward = -301.53745840919385, Average Loss = 30.0707, Epsilon: 0.6088145090359074\n",
      "Episode 99: Total Reward = -74.94003342901715, Average Loss = 16.9703, Epsilon: 0.6057704364907278\n",
      "Episode 100: Total Reward = -178.5617816671803, Average Loss = 18.4404, Epsilon: 0.6027415843082742\n",
      "Episode 101: Total Reward = -99.80206552767335, Average Loss = 27.2340, Epsilon: 0.5997278763867329\n",
      "Episode 102: Total Reward = -79.16662451080784, Average Loss = 16.4575, Epsilon: 0.5967292370047992\n",
      "Episode 103: Total Reward = -120.80081722726536, Average Loss = 16.6601, Epsilon: 0.5937455908197752\n",
      "Episode 104: Total Reward = -88.16246037622501, Average Loss = 15.9034, Epsilon: 0.5907768628656763\n",
      "Episode 105: Total Reward = 53.613398508864094, Average Loss = 18.7838, Epsilon: 0.5878229785513479\n",
      "Episode 106: Total Reward = -154.45708808110768, Average Loss = 16.3700, Epsilon: 0.5848838636585911\n",
      "Episode 107: Total Reward = -679.2496298557385, Average Loss = 16.8752, Epsilon: 0.5819594443402982\n",
      "Episode 108: Total Reward = -43.104778936447545, Average Loss = 16.3080, Epsilon: 0.5790496471185967\n",
      "Episode 109: Total Reward = -43.6785740253668, Average Loss = 15.6790, Epsilon: 0.5761543988830038\n",
      "Episode 110: Total Reward = -71.48448494519224, Average Loss = 15.9959, Epsilon: 0.5732736268885887\n",
      "Episode 111: Total Reward = -69.45729883640982, Average Loss = 15.4298, Epsilon: 0.5704072587541458\n",
      "Episode 112: Total Reward = -420.3095788980917, Average Loss = 17.1690, Epsilon: 0.567555222460375\n",
      "Episode 113: Total Reward = -220.5735253371475, Average Loss = 15.2397, Epsilon: 0.5647174463480732\n",
      "Episode 114: Total Reward = -25.882720175134068, Average Loss = 15.6927, Epsilon: 0.5618938591163328\n",
      "Episode 115: Total Reward = -736.9209047036113, Average Loss = 13.9288, Epsilon: 0.5590843898207511\n",
      "Episode 116: Total Reward = -96.60059244612661, Average Loss = 14.1525, Epsilon: 0.5562889678716474\n",
      "Episode 117: Total Reward = -43.00898456019354, Average Loss = 12.8240, Epsilon: 0.5535075230322891\n",
      "Episode 118: Total Reward = -12.861293158437206, Average Loss = 12.1661, Epsilon: 0.5507399854171277\n",
      "Episode 119: Total Reward = -120.88774780974511, Average Loss = 12.5235, Epsilon: 0.547986285490042\n",
      "Episode 120: Total Reward = 33.48848969925044, Average Loss = 13.6325, Epsilon: 0.5452463540625918\n",
      "Episode 121: Total Reward = -72.735263603791, Average Loss = 14.7846, Epsilon: 0.5425201222922789\n",
      "Episode 122: Total Reward = -16.827594313858043, Average Loss = 12.8728, Epsilon: 0.5398075216808175\n",
      "Episode 123: Total Reward = -357.70541484184747, Average Loss = 10.6151, Epsilon: 0.5371084840724134\n",
      "Episode 124: Total Reward = -53.07970706151666, Average Loss = 11.8482, Epsilon: 0.5344229416520513\n",
      "Episode 125: Total Reward = -36.32224435686998, Average Loss = 11.8255, Epsilon: 0.531750826943791\n",
      "Episode 126: Total Reward = -3243.164637781505, Average Loss = 13.2965, Epsilon: 0.5290920728090721\n",
      "Episode 127: Total Reward = -233.94209481522873, Average Loss = 13.6732, Epsilon: 0.5264466124450268\n",
      "Episode 128: Total Reward = 0.7837441993424363, Average Loss = 10.9525, Epsilon: 0.5238143793828016\n",
      "Episode 129: Total Reward = -301.1537453229914, Average Loss = 12.6662, Epsilon: 0.5211953074858876\n",
      "Episode 130: Total Reward = -138.49668964205173, Average Loss = 13.6908, Epsilon: 0.5185893309484582\n",
      "Episode 131: Total Reward = -174.03733995755294, Average Loss = 14.0427, Epsilon: 0.5159963842937159\n",
      "Episode 132: Total Reward = 36.913538805950225, Average Loss = 12.2137, Epsilon: 0.5134164023722473\n",
      "Episode 133: Total Reward = -4037.266172320291, Average Loss = 13.5329, Epsilon: 0.510849320360386\n",
      "Episode 134: Total Reward = -130.51708553031037, Average Loss = 14.3794, Epsilon: 0.5082950737585841\n",
      "Episode 135: Total Reward = -136.6223720641584, Average Loss = 22.3007, Epsilon: 0.5057535983897912\n",
      "Episode 136: Total Reward = -34.629927627323724, Average Loss = 16.5611, Epsilon: 0.5032248303978422\n",
      "Episode 137: Total Reward = -90.69702816165064, Average Loss = 13.0032, Epsilon: 0.500708706245853\n",
      "Episode 138: Total Reward = -86.76208919572596, Average Loss = 14.1144, Epsilon: 0.4982051627146237\n",
      "Episode 139: Total Reward = -36.06255173633551, Average Loss = 15.5988, Epsilon: 0.49571413690105054\n",
      "Episode 140: Total Reward = -60.001652231939204, Average Loss = 15.1331, Epsilon: 0.4932355662165453\n",
      "Episode 141: Total Reward = -3474.107353963185, Average Loss = 15.1620, Epsilon: 0.4907693883854626\n",
      "Episode 142: Total Reward = -32.809204823801906, Average Loss = 15.0100, Epsilon: 0.4883155414435353\n",
      "Episode 143: Total Reward = -31.269909248867435, Average Loss = 14.5669, Epsilon: 0.4858739637363176\n",
      "Episode 144: Total Reward = -53.480038672567645, Average Loss = 13.8018, Epsilon: 0.483444593917636\n",
      "Episode 145: Total Reward = -303.63066760435515, Average Loss = 15.8909, Epsilon: 0.4810273709480478\n",
      "Episode 146: Total Reward = -1526.6094416976503, Average Loss = 13.5040, Epsilon: 0.47862223409330756\n",
      "Episode 147: Total Reward = -16.472015677874708, Average Loss = 12.8338, Epsilon: 0.47622912292284103\n",
      "Episode 148: Total Reward = -461.8343878618531, Average Loss = 12.4955, Epsilon: 0.4738479773082268\n",
      "Episode 149: Total Reward = -552.804507141386, Average Loss = 13.7955, Epsilon: 0.47147873742168567\n",
      "Episode 150: Total Reward = -1.0223776266240918, Average Loss = 20.9297, Epsilon: 0.46912134373457726\n",
      "Episode 151: Total Reward = 3.7761733599598557, Average Loss = 20.8554, Epsilon: 0.46677573701590436\n",
      "Episode 152: Total Reward = -295.6434090006675, Average Loss = 20.2339, Epsilon: 0.46444185833082485\n",
      "Episode 153: Total Reward = -10.9952058685531, Average Loss = 19.4235, Epsilon: 0.46211964903917074\n",
      "Episode 154: Total Reward = -37.04891329341086, Average Loss = 17.5194, Epsilon: 0.4598090507939749\n",
      "Episode 155: Total Reward = -12.259408836480489, Average Loss = 16.2535, Epsilon: 0.457510005540005\n",
      "Episode 156: Total Reward = -284.9983848689051, Average Loss = 16.6713, Epsilon: 0.45522245551230495\n",
      "Episode 157: Total Reward = -18.659596462649304, Average Loss = 17.1973, Epsilon: 0.4529463432347434\n",
      "Episode 158: Total Reward = -3345.0125226992695, Average Loss = 15.3185, Epsilon: 0.4506816115185697\n",
      "Episode 159: Total Reward = -0.48912515344783003, Average Loss = 16.3282, Epsilon: 0.4484282034609769\n",
      "Episode 160: Total Reward = -878.3079716305759, Average Loss = 16.2723, Epsilon: 0.446186062443672\n",
      "Episode 161: Total Reward = -573.3436200735202, Average Loss = 16.5301, Epsilon: 0.4439551321314536\n",
      "Episode 162: Total Reward = -3398.7730414268513, Average Loss = 15.1281, Epsilon: 0.4417353564707963\n",
      "Episode 163: Total Reward = -28.47883949479842, Average Loss = 18.2106, Epsilon: 0.43952667968844233\n",
      "Episode 164: Total Reward = -2649.398950672436, Average Loss = 18.4738, Epsilon: 0.43732904629000013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 165: Total Reward = -911.9903722687558, Average Loss = 27.5942, Epsilon: 0.4351424010585501\n",
      "Episode 166: Total Reward = -52.58547374737552, Average Loss = 22.9426, Epsilon: 0.43296668905325736\n",
      "Episode 167: Total Reward = -3548.6141353045323, Average Loss = 21.3963, Epsilon: 0.43080185560799106\n",
      "Episode 168: Total Reward = -16.824840768318992, Average Loss = 15.1520, Epsilon: 0.4286478463299511\n",
      "Episode 169: Total Reward = -68.14208906591158, Average Loss = 12.8145, Epsilon: 0.42650460709830135\n",
      "Episode 170: Total Reward = -3253.891473285829, Average Loss = 17.2326, Epsilon: 0.42437208406280985\n",
      "Episode 171: Total Reward = 29.756639684723382, Average Loss = 17.5600, Epsilon: 0.4222502236424958\n",
      "Episode 172: Total Reward = 11.124708532054157, Average Loss = 13.1657, Epsilon: 0.42013897252428334\n",
      "Episode 173: Total Reward = -3555.732429070677, Average Loss = 17.2377, Epsilon: 0.4180382776616619\n",
      "Episode 174: Total Reward = -3191.2178315293254, Average Loss = 17.6696, Epsilon: 0.4159480862733536\n",
      "Episode 175: Total Reward = -26.002251426689753, Average Loss = 13.1020, Epsilon: 0.41386834584198684\n",
      "Episode 176: Total Reward = -208.97495483961688, Average Loss = 20.7520, Epsilon: 0.4117990041127769\n",
      "Episode 177: Total Reward = 40.19651322073457, Average Loss = 37.7903, Epsilon: 0.40974000909221303\n",
      "Episode 178: Total Reward = 30.151248503595696, Average Loss = 21.6713, Epsilon: 0.40769130904675194\n",
      "Episode 179: Total Reward = -26.788576484827715, Average Loss = 26.7035, Epsilon: 0.40565285250151817\n",
      "Episode 180: Total Reward = -3742.8098935543076, Average Loss = 66.6347, Epsilon: 0.4036245882390106\n",
      "Episode 181: Total Reward = 18.13551397104756, Average Loss = 47.4716, Epsilon: 0.4016064652978155\n",
      "Episode 182: Total Reward = 40.24060197723446, Average Loss = 65.8939, Epsilon: 0.3995984329713264\n",
      "Episode 183: Total Reward = -16.882090952629028, Average Loss = 90.1905, Epsilon: 0.3976004408064698\n",
      "Episode 184: Total Reward = 35.56573860688752, Average Loss = 77.2300, Epsilon: 0.39561243860243744\n",
      "Episode 185: Total Reward = 16.077619517440638, Average Loss = 89.3595, Epsilon: 0.3936343764094253\n",
      "Episode 186: Total Reward = 26.37758584244179, Average Loss = 106.0319, Epsilon: 0.39166620452737816\n",
      "Episode 187: Total Reward = -140.7447248600588, Average Loss = 95.2916, Epsilon: 0.3897078735047413\n",
      "Episode 188: Total Reward = 30.353210802394955, Average Loss = 143.5242, Epsilon: 0.3877593341372176\n",
      "Episode 189: Total Reward = -98.08577953548301, Average Loss = 163.3289, Epsilon: 0.3858205374665315\n",
      "Episode 190: Total Reward = 4.863592766695334, Average Loss = 116.0169, Epsilon: 0.38389143477919885\n",
      "Episode 191: Total Reward = -47.4876674392079, Average Loss = 120.9200, Epsilon: 0.3819719776053028\n",
      "Episode 192: Total Reward = -16.522082346951862, Average Loss = 166.6298, Epsilon: 0.3800621177172763\n",
      "Episode 193: Total Reward = 37.755180858765755, Average Loss = 120.3525, Epsilon: 0.37816180712868996\n",
      "Episode 194: Total Reward = -32.02073719711137, Average Loss = 158.0547, Epsilon: 0.37627099809304654\n",
      "Episode 195: Total Reward = -14.958329133666638, Average Loss = 87.7130, Epsilon: 0.3743896431025813\n",
      "Episode 196: Total Reward = -10.284710919751546, Average Loss = 84.1511, Epsilon: 0.37251769488706843\n",
      "Episode 197: Total Reward = 1.3990760605658608, Average Loss = 101.1560, Epsilon: 0.3706551064126331\n",
      "Episode 198: Total Reward = -48.34501956503292, Average Loss = 91.5213, Epsilon: 0.36880183088056995\n",
      "Episode 199: Total Reward = -0.9083947389536178, Average Loss = 78.0858, Epsilon: 0.3669578217261671\n",
      "Episode 200: Total Reward = -81.1736627350763, Average Loss = 78.7542, Epsilon: 0.36512303261753626\n",
      "Episode 201: Total Reward = -56.74758415152323, Average Loss = 111.5355, Epsilon: 0.3632974174544486\n",
      "Episode 202: Total Reward = -5.270508851828836, Average Loss = 103.4629, Epsilon: 0.3614809303671764\n",
      "Episode 203: Total Reward = -49.18882962002898, Average Loss = 112.1266, Epsilon: 0.3596735257153405\n",
      "Episode 204: Total Reward = -73.60087173393953, Average Loss = 120.6575, Epsilon: 0.3578751580867638\n",
      "Episode 205: Total Reward = -48.743607710525936, Average Loss = 73.7112, Epsilon: 0.35608578229633\n",
      "Episode 206: Total Reward = -183.3994897865631, Average Loss = 95.0747, Epsilon: 0.3543053533848483\n",
      "Episode 207: Total Reward = -30.624285891305348, Average Loss = 79.0936, Epsilon: 0.35253382661792404\n",
      "Episode 208: Total Reward = -60.81860977080536, Average Loss = 103.7592, Epsilon: 0.3507711574848344\n",
      "Episode 209: Total Reward = -3376.083672739014, Average Loss = 86.6289, Epsilon: 0.34901730169741024\n",
      "Episode 210: Total Reward = -63.4367988430853, Average Loss = 59.8677, Epsilon: 0.3472722151889232\n",
      "Episode 211: Total Reward = -107.33537435409129, Average Loss = 71.0317, Epsilon: 0.3455358541129786\n",
      "Episode 212: Total Reward = -19.839550916617043, Average Loss = 50.9955, Epsilon: 0.3438081748424137\n",
      "Episode 213: Total Reward = -9.119817199659195, Average Loss = 63.6872, Epsilon: 0.3420891339682016\n",
      "Episode 214: Total Reward = -0.2730415927829597, Average Loss = 46.2857, Epsilon: 0.3403786882983606\n",
      "Episode 215: Total Reward = -80.66831909552901, Average Loss = 46.2967, Epsilon: 0.3386767948568688\n",
      "Episode 216: Total Reward = -393.07063938695853, Average Loss = 40.7109, Epsilon: 0.33698341088258443\n",
      "Episode 217: Total Reward = -3338.7752422009758, Average Loss = 38.0234, Epsilon: 0.3352984938281715\n",
      "Episode 218: Total Reward = 17.69742217041241, Average Loss = 37.9615, Epsilon: 0.33362200135903064\n",
      "Episode 219: Total Reward = -223.99050612567174, Average Loss = 34.1662, Epsilon: 0.33195389135223546\n",
      "Episode 220: Total Reward = -27.197168287738748, Average Loss = 32.4973, Epsilon: 0.3302941218954743\n",
      "Episode 221: Total Reward = -196.2345780313126, Average Loss = 31.6903, Epsilon: 0.32864265128599696\n",
      "Episode 222: Total Reward = -263.2299223123978, Average Loss = 31.1098, Epsilon: 0.326999438029567\n",
      "Episode 223: Total Reward = -5.428237743045969, Average Loss = 38.5156, Epsilon: 0.3253644408394192\n",
      "Episode 224: Total Reward = -170.8523095216422, Average Loss = 38.6467, Epsilon: 0.3237376186352221\n",
      "Episode 225: Total Reward = 1.4649056589567522, Average Loss = 45.7748, Epsilon: 0.322118930542046\n",
      "Episode 226: Total Reward = -24.756008046731566, Average Loss = 49.9898, Epsilon: 0.32050833588933575\n",
      "Episode 227: Total Reward = -20.618128677102092, Average Loss = 32.8763, Epsilon: 0.31890579420988907\n",
      "Episode 228: Total Reward = -0.5841943607740347, Average Loss = 33.4889, Epsilon: 0.3173112652388396\n",
      "Episode 229: Total Reward = -472.5691922345405, Average Loss = 38.7943, Epsilon: 0.3157247089126454\n",
      "Episode 230: Total Reward = -147.40226573756752, Average Loss = 30.7036, Epsilon: 0.3141460853680822\n",
      "Episode 231: Total Reward = 51.430945214103474, Average Loss = 40.8730, Epsilon: 0.3125753549412418\n",
      "Episode 232: Total Reward = -32.56898259027679, Average Loss = 48.2114, Epsilon: 0.31101247816653554\n",
      "Episode 233: Total Reward = -16.307983018756985, Average Loss = 32.7115, Epsilon: 0.30945741577570285\n",
      "Episode 234: Total Reward = 14.482196661247428, Average Loss = 39.5160, Epsilon: 0.3079101286968243\n",
      "Episode 235: Total Reward = -22.914906699017564, Average Loss = 38.2835, Epsilon: 0.3063705780533402\n",
      "Episode 236: Total Reward = -4.376247817588009, Average Loss = 38.6790, Epsilon: 0.30483872516307353\n",
      "Episode 237: Total Reward = -31.447487708321518, Average Loss = 40.8238, Epsilon: 0.3033145315372582\n",
      "Episode 238: Total Reward = -79.96046641271204, Average Loss = 36.7960, Epsilon: 0.3017979588795719\n",
      "Episode 239: Total Reward = -406.8620017250667, Average Loss = 35.4445, Epsilon: 0.30028896908517405\n",
      "Episode 240: Total Reward = -7.7325059816812285, Average Loss = 37.8219, Epsilon: 0.2987875242397482\n",
      "Episode 241: Total Reward = -2.7809542487264025, Average Loss = 43.5842, Epsilon: 0.29729358661854943\n",
      "Episode 242: Total Reward = -338.88632743176254, Average Loss = 38.0631, Epsilon: 0.29580711868545667\n",
      "Episode 243: Total Reward = -61.26710063450671, Average Loss = 39.2393, Epsilon: 0.2943280830920294\n",
      "Episode 244: Total Reward = -804.0027581422262, Average Loss = 32.8281, Epsilon: 0.29285644267656924\n",
      "Episode 245: Total Reward = -30.272884512488744, Average Loss = 29.5826, Epsilon: 0.2913921604631864\n",
      "Episode 246: Total Reward = -14.13589645107011, Average Loss = 33.6949, Epsilon: 0.28993519966087045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 247: Total Reward = -43.42316522922563, Average Loss = 36.4733, Epsilon: 0.2884855236625661\n",
      "Episode 248: Total Reward = -55.157688914288116, Average Loss = 40.1694, Epsilon: 0.28704309604425327\n",
      "Episode 249: Total Reward = 42.58411459269763, Average Loss = 31.1494, Epsilon: 0.285607880564032\n",
      "Episode 250: Total Reward = 5.631982732541601, Average Loss = 42.8601, Epsilon: 0.28417984116121187\n",
      "Episode 251: Total Reward = -317.1511354944861, Average Loss = 37.7134, Epsilon: 0.2827589419554058\n",
      "Episode 252: Total Reward = 46.192760509129755, Average Loss = 36.1128, Epsilon: 0.28134514724562876\n",
      "Episode 253: Total Reward = -80.08767767584621, Average Loss = 40.5044, Epsilon: 0.2799384215094006\n",
      "Episode 254: Total Reward = -85.11894515388538, Average Loss = 48.2459, Epsilon: 0.27853872940185365\n",
      "Episode 255: Total Reward = 6.450600426597816, Average Loss = 48.7585, Epsilon: 0.27714603575484437\n",
      "Episode 256: Total Reward = -52.474560591722266, Average Loss = 52.5472, Epsilon: 0.2757603055760701\n",
      "Episode 257: Total Reward = -22.75684989486045, Average Loss = 38.7282, Epsilon: 0.2743815040481898\n",
      "Episode 258: Total Reward = -16.32026685787649, Average Loss = 39.3762, Epsilon: 0.2730095965279488\n",
      "Episode 259: Total Reward = -51.36330257071333, Average Loss = 42.5842, Epsilon: 0.27164454854530906\n",
      "Episode 260: Total Reward = -198.56963133975395, Average Loss = 42.2483, Epsilon: 0.2702863258025825\n",
      "Episode 261: Total Reward = -545.2875466536416, Average Loss = 54.2950, Epsilon: 0.2689348941735696\n",
      "Episode 262: Total Reward = -278.2062830362005, Average Loss = 53.5724, Epsilon: 0.26759021970270175\n",
      "Episode 263: Total Reward = -55.71578144631685, Average Loss = 57.3023, Epsilon: 0.2662522686041882\n",
      "Episode 264: Total Reward = -277.6255994394668, Average Loss = 60.8181, Epsilon: 0.2649210072611673\n",
      "Episode 265: Total Reward = -95.61379989011147, Average Loss = 54.9413, Epsilon: 0.26359640222486147\n",
      "Episode 266: Total Reward = -93.8454675579781, Average Loss = 61.2902, Epsilon: 0.26227842021373715\n",
      "Episode 267: Total Reward = -270.1889116815551, Average Loss = 52.5867, Epsilon: 0.2609670281126685\n",
      "Episode 268: Total Reward = -97.36850571964686, Average Loss = 59.5919, Epsilon: 0.25966219297210513\n",
      "Episode 269: Total Reward = -215.34841867139704, Average Loss = 57.5309, Epsilon: 0.2583638820072446\n",
      "Episode 270: Total Reward = -183.52369959112332, Average Loss = 39.5034, Epsilon: 0.2570720625972084\n",
      "Episode 271: Total Reward = -244.4140750871873, Average Loss = 42.7966, Epsilon: 0.25578670228422234\n",
      "Episode 272: Total Reward = -1214.0362712009664, Average Loss = 39.0451, Epsilon: 0.25450776877280124\n",
      "Episode 273: Total Reward = -401.0470344837281, Average Loss = 35.7602, Epsilon: 0.2532352299289372\n",
      "Episode 274: Total Reward = -787.9925546770348, Average Loss = 35.2996, Epsilon: 0.2519690537792925\n",
      "Episode 275: Total Reward = -1723.0654375830134, Average Loss = 33.8306, Epsilon: 0.2507092085103961\n",
      "Episode 276: Total Reward = -163.53163337805134, Average Loss = 35.6147, Epsilon: 0.2494556624678441\n",
      "Episode 277: Total Reward = -78.1210144613053, Average Loss = 34.1837, Epsilon: 0.24820838415550486\n",
      "Episode 278: Total Reward = -4214.023592135966, Average Loss = 28.4771, Epsilon: 0.24696734223472733\n",
      "Episode 279: Total Reward = -842.4092703881558, Average Loss = 23.5679, Epsilon: 0.2457325055235537\n",
      "Episode 280: Total Reward = -2213.4585984209084, Average Loss = 18.8863, Epsilon: 0.24450384299593592\n",
      "Episode 281: Total Reward = -93.73134375074436, Average Loss = 19.8781, Epsilon: 0.24328132378095624\n",
      "Episode 282: Total Reward = -2743.542421844874, Average Loss = 19.5704, Epsilon: 0.24206491716205145\n",
      "Episode 283: Total Reward = -75.94023658896342, Average Loss = 17.6418, Epsilon: 0.2408545925762412\n",
      "Episode 284: Total Reward = -1339.9149604893494, Average Loss = 14.8362, Epsilon: 0.23965031961336\n",
      "Episode 285: Total Reward = -102.02973260348722, Average Loss = 15.8177, Epsilon: 0.2384520680152932\n",
      "Episode 286: Total Reward = -127.90627511517374, Average Loss = 10.5373, Epsilon: 0.23725980767521673\n",
      "Episode 287: Total Reward = -507.93054884971104, Average Loss = 10.9573, Epsilon: 0.23607350863684065\n",
      "Episode 288: Total Reward = -1780.0641707074678, Average Loss = 9.3039, Epsilon: 0.23489314109365644\n",
      "Episode 289: Total Reward = -1237.1150004822234, Average Loss = 9.1004, Epsilon: 0.23371867538818816\n",
      "Episode 290: Total Reward = -55.47877057157134, Average Loss = 7.9492, Epsilon: 0.23255008201124722\n",
      "Episode 291: Total Reward = -2139.8226933402298, Average Loss = 8.7695, Epsilon: 0.231387331601191\n",
      "Episode 292: Total Reward = -1437.0258489257894, Average Loss = 7.6516, Epsilon: 0.23023039494318503\n",
      "Episode 293: Total Reward = -32.29076043913663, Average Loss = 7.3824, Epsilon: 0.2290792429684691\n",
      "Episode 294: Total Reward = -4232.609970230561, Average Loss = 6.5508, Epsilon: 0.22793384675362674\n",
      "Episode 295: Total Reward = -238.28579238812463, Average Loss = 5.2784, Epsilon: 0.22679417751985861\n",
      "Episode 296: Total Reward = -4164.364800266012, Average Loss = 5.4594, Epsilon: 0.22566020663225933\n",
      "Episode 297: Total Reward = -16.004306701495906, Average Loss = 5.7485, Epsilon: 0.22453190559909803\n",
      "Episode 298: Total Reward = -148.02292705235698, Average Loss = 5.9856, Epsilon: 0.22340924607110255\n",
      "Episode 299: Total Reward = -2537.499643484865, Average Loss = 5.4956, Epsilon: 0.22229219984074702\n",
      "Episode 300: Total Reward = -103.40566989640408, Average Loss = 10.2193, Epsilon: 0.2211807388415433\n",
      "Episode 301: Total Reward = -148.05108059829968, Average Loss = 7.3239, Epsilon: 0.22007483514733558\n",
      "Episode 302: Total Reward = -137.57755900000464, Average Loss = 6.0203, Epsilon: 0.2189744609715989\n",
      "Episode 303: Total Reward = -152.0971607840418, Average Loss = 5.8040, Epsilon: 0.2178795886667409\n",
      "Episode 304: Total Reward = -116.06450646458909, Average Loss = 5.6176, Epsilon: 0.2167901907234072\n",
      "Episode 305: Total Reward = -207.42038029650917, Average Loss = 7.0352, Epsilon: 0.21570623976979014\n",
      "Episode 306: Total Reward = -114.23783738629322, Average Loss = 7.2472, Epsilon: 0.21462770857094118\n",
      "Episode 307: Total Reward = -129.84492830544988, Average Loss = 23.4322, Epsilon: 0.21355457002808648\n",
      "Episode 308: Total Reward = -89.01585229474287, Average Loss = 16.5661, Epsilon: 0.21248679717794605\n",
      "Episode 309: Total Reward = -91.25130049369659, Average Loss = 19.5157, Epsilon: 0.21142436319205632\n",
      "Episode 310: Total Reward = -103.22010696088687, Average Loss = 7.6874, Epsilon: 0.21036724137609603\n",
      "Episode 311: Total Reward = -105.48071465451204, Average Loss = 14.5033, Epsilon: 0.20931540516921554\n",
      "Episode 312: Total Reward = -46.734838087480114, Average Loss = 8.4677, Epsilon: 0.20826882814336947\n",
      "Episode 313: Total Reward = -48.901873191057504, Average Loss = 7.2530, Epsilon: 0.20722748400265262\n",
      "Episode 314: Total Reward = -39.12209219963657, Average Loss = 6.9326, Epsilon: 0.20619134658263935\n",
      "Episode 315: Total Reward = -148.64426988118382, Average Loss = 10.3171, Epsilon: 0.20516038984972615\n",
      "Episode 316: Total Reward = -104.1869501126231, Average Loss = 31.8737, Epsilon: 0.2041345879004775\n",
      "Episode 317: Total Reward = -128.38049110132118, Average Loss = 16.8285, Epsilon: 0.2031139149609751\n",
      "Episode 318: Total Reward = -47.200958693161866, Average Loss = 15.1129, Epsilon: 0.20209834538617025\n",
      "Episode 319: Total Reward = -80.69167196967408, Average Loss = 26.4354, Epsilon: 0.2010878536592394\n",
      "Episode 320: Total Reward = -25.874659966323478, Average Loss = 19.9423, Epsilon: 0.2000824143909432\n",
      "Episode 321: Total Reward = -21.569602838459005, Average Loss = 7.5004, Epsilon: 0.19908200231898848\n",
      "Episode 322: Total Reward = -18.59418049120268, Average Loss = 12.5433, Epsilon: 0.19808659230739353\n",
      "Episode 323: Total Reward = -90.13754398209588, Average Loss = 15.3907, Epsilon: 0.19709615934585656\n",
      "Episode 324: Total Reward = -5.2911032774889435, Average Loss = 8.8712, Epsilon: 0.19611067854912728\n",
      "Episode 325: Total Reward = 2.1473315215803126, Average Loss = 18.3701, Epsilon: 0.19513012515638165\n",
      "Episode 326: Total Reward = -101.75359432164656, Average Loss = 15.9180, Epsilon: 0.19415447453059972\n",
      "Episode 327: Total Reward = -95.10979005661906, Average Loss = 16.3202, Epsilon: 0.19318370215794672\n",
      "Episode 328: Total Reward = -62.0995990730631, Average Loss = 16.6612, Epsilon: 0.192217783647157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 329: Total Reward = -77.98133113552453, Average Loss = 11.1215, Epsilon: 0.1912566947289212\n",
      "Episode 330: Total Reward = 13.308854581561121, Average Loss = 29.6953, Epsilon: 0.1903004112552766\n",
      "Episode 331: Total Reward = -113.1366517292366, Average Loss = 14.9541, Epsilon: 0.18934890919900021\n",
      "Episode 332: Total Reward = -39.432061402474446, Average Loss = 22.7792, Epsilon: 0.18840216465300522\n",
      "Episode 333: Total Reward = -2.069457624535474, Average Loss = 29.8660, Epsilon: 0.18746015382974018\n",
      "Episode 334: Total Reward = -8.183496252071421, Average Loss = 15.7896, Epsilon: 0.1865228530605915\n",
      "Episode 335: Total Reward = -37.71877098606737, Average Loss = 12.3652, Epsilon: 0.18559023879528855\n",
      "Episode 336: Total Reward = 15.967337766913971, Average Loss = 19.6892, Epsilon: 0.1846622876013121\n",
      "Episode 337: Total Reward = 17.072433643081, Average Loss = 24.1560, Epsilon: 0.18373897616330553\n",
      "Episode 338: Total Reward = -18.260569953605483, Average Loss = 16.8248, Epsilon: 0.182820281282489\n",
      "Episode 339: Total Reward = -29.064922247073284, Average Loss = 28.3393, Epsilon: 0.18190617987607657\n",
      "Episode 340: Total Reward = -40.009381719621686, Average Loss = 11.7642, Epsilon: 0.18099664897669618\n",
      "Episode 341: Total Reward = 19.990827823536335, Average Loss = 20.6851, Epsilon: 0.1800916657318127\n",
      "Episode 342: Total Reward = -34.78252273119034, Average Loss = 17.8851, Epsilon: 0.17919120740315364\n",
      "Episode 343: Total Reward = -38.97704077538975, Average Loss = 25.0759, Epsilon: 0.17829525136613786\n",
      "Episode 344: Total Reward = -59.52921865502512, Average Loss = 27.9912, Epsilon: 0.17740377510930716\n",
      "Episode 345: Total Reward = -21.95591595960086, Average Loss = 28.9361, Epsilon: 0.17651675623376062\n",
      "Episode 346: Total Reward = -1.3871473111370847, Average Loss = 26.9763, Epsilon: 0.1756341724525918\n",
      "Episode 347: Total Reward = -3026.421737786432, Average Loss = 27.4988, Epsilon: 0.17475600159032884\n",
      "Episode 348: Total Reward = -31.934912544002188, Average Loss = 46.1736, Epsilon: 0.17388222158237718\n",
      "Episode 349: Total Reward = -75.74690443739459, Average Loss = 49.6575, Epsilon: 0.1730128104744653\n",
      "Episode 350: Total Reward = 27.641892768407246, Average Loss = 28.0779, Epsilon: 0.17214774642209296\n",
      "Episode 351: Total Reward = -62.72325609158129, Average Loss = 42.6813, Epsilon: 0.1712870076899825\n",
      "Episode 352: Total Reward = -37.86833612099457, Average Loss = 68.8521, Epsilon: 0.17043057265153258\n",
      "Episode 353: Total Reward = -70.6818650204306, Average Loss = 67.5788, Epsilon: 0.16957841978827493\n",
      "Episode 354: Total Reward = -33.66714386805087, Average Loss = 31.9414, Epsilon: 0.16873052768933355\n",
      "Episode 355: Total Reward = -70.33930529392744, Average Loss = 57.6229, Epsilon: 0.1678868750508869\n",
      "Episode 356: Total Reward = -34.05356060792933, Average Loss = 58.5679, Epsilon: 0.16704744067563246\n",
      "Episode 357: Total Reward = -75.39337228835535, Average Loss = 139.3206, Epsilon: 0.1662122034722543\n",
      "Episode 358: Total Reward = -38.4665113900993, Average Loss = 39.2031, Epsilon: 0.16538114245489302\n",
      "Episode 359: Total Reward = -16.421703849507054, Average Loss = 28.3092, Epsilon: 0.16455423674261854\n",
      "Episode 360: Total Reward = 12.64260616924976, Average Loss = 32.9978, Epsilon: 0.16373146555890544\n",
      "Episode 361: Total Reward = 16.000372835283812, Average Loss = 62.9906, Epsilon: 0.16291280823111093\n",
      "Episode 362: Total Reward = -63.66012028819099, Average Loss = 62.8234, Epsilon: 0.16209824418995536\n",
      "Episode 363: Total Reward = -60.43075018453831, Average Loss = 63.1104, Epsilon: 0.16128775296900558\n",
      "Episode 364: Total Reward = -14.318511089435333, Average Loss = 49.6225, Epsilon: 0.16048131420416054\n",
      "Episode 365: Total Reward = -21.82220545585946, Average Loss = 23.6518, Epsilon: 0.15967890763313974\n",
      "Episode 366: Total Reward = -51.62552045171693, Average Loss = 60.2770, Epsilon: 0.15888051309497406\n",
      "Episode 367: Total Reward = -30.35578795621663, Average Loss = 23.1453, Epsilon: 0.1580861105294992\n",
      "Episode 368: Total Reward = -40.96176643050323, Average Loss = 51.4925, Epsilon: 0.1572956799768517\n",
      "Episode 369: Total Reward = -46.236823991610294, Average Loss = 53.6884, Epsilon: 0.15650920157696743\n",
      "Episode 370: Total Reward = -28.522542952488124, Average Loss = 56.0231, Epsilon: 0.1557266555690826\n",
      "Episode 371: Total Reward = -37.51893889249162, Average Loss = 38.8995, Epsilon: 0.1549480222912372\n",
      "Episode 372: Total Reward = -2.6457594250398984, Average Loss = 19.6509, Epsilon: 0.15417328217978102\n",
      "Episode 373: Total Reward = -96.13287730899496, Average Loss = 54.6133, Epsilon: 0.1534024157688821\n",
      "Episode 374: Total Reward = -51.18340115041241, Average Loss = 37.8992, Epsilon: 0.1526354036900377\n",
      "Episode 375: Total Reward = -47.25696563341789, Average Loss = 84.1222, Epsilon: 0.1518722266715875\n",
      "Episode 376: Total Reward = -69.7783917785699, Average Loss = 33.1510, Epsilon: 0.15111286553822956\n",
      "Episode 377: Total Reward = -48.50156661743439, Average Loss = 18.0645, Epsilon: 0.15035730121053842\n",
      "Episode 378: Total Reward = -36.31119611692138, Average Loss = 30.4501, Epsilon: 0.14960551470448571\n",
      "Episode 379: Total Reward = -53.85511243976578, Average Loss = 30.9876, Epsilon: 0.14885748713096328\n",
      "Episode 380: Total Reward = -72.54459277724771, Average Loss = 48.0542, Epsilon: 0.14811319969530845\n",
      "Episode 381: Total Reward = -74.8060638328354, Average Loss = 15.6724, Epsilon: 0.1473726336968319\n",
      "Episode 382: Total Reward = -53.61132976638096, Average Loss = 17.2265, Epsilon: 0.14663577052834775\n",
      "Episode 383: Total Reward = -48.03535112496256, Average Loss = 19.9056, Epsilon: 0.14590259167570602\n",
      "Episode 384: Total Reward = -123.06639733625074, Average Loss = 17.6751, Epsilon: 0.1451730787173275\n",
      "Episode 385: Total Reward = -45.69542655238818, Average Loss = 12.7383, Epsilon: 0.14444721332374086\n",
      "Episode 386: Total Reward = -88.89722797473932, Average Loss = 17.1418, Epsilon: 0.14372497725712216\n",
      "Episode 387: Total Reward = -99.10072837539609, Average Loss = 37.4062, Epsilon: 0.14300635237083656\n",
      "Episode 388: Total Reward = -41.92025135081223, Average Loss = 50.9537, Epsilon: 0.14229132060898236\n",
      "Episode 389: Total Reward = -34.83050483358524, Average Loss = 18.4956, Epsilon: 0.14157986400593744\n",
      "Episode 390: Total Reward = 0.04891473735530383, Average Loss = 16.1412, Epsilon: 0.14087196468590776\n",
      "Episode 391: Total Reward = -34.75213953483191, Average Loss = 23.8546, Epsilon: 0.14016760486247823\n",
      "Episode 392: Total Reward = -32.39857969584483, Average Loss = 26.2417, Epsilon: 0.13946676683816583\n",
      "Episode 393: Total Reward = -86.30108647993144, Average Loss = 40.5523, Epsilon: 0.138769433003975\n",
      "Episode 394: Total Reward = -53.5845501518173, Average Loss = 28.7855, Epsilon: 0.13807558583895513\n",
      "Episode 395: Total Reward = -17.798931348846793, Average Loss = 64.6478, Epsilon: 0.13738520790976036\n",
      "Episode 396: Total Reward = -17.432427907999767, Average Loss = 42.0166, Epsilon: 0.13669828187021155\n",
      "Episode 397: Total Reward = -84.07098033958134, Average Loss = 33.8305, Epsilon: 0.13601479046086049\n",
      "Episode 398: Total Reward = -24.65910300491781, Average Loss = 50.2116, Epsilon: 0.1353347165085562\n",
      "Episode 399: Total Reward = -80.88789004434196, Average Loss = 10.2455, Epsilon: 0.1346580429260134\n",
      "Episode 400: Total Reward = -32.8566611069848, Average Loss = 8.2780, Epsilon: 0.13398475271138335\n",
      "Episode 401: Total Reward = -31.425063517565874, Average Loss = 10.9704, Epsilon: 0.13331482894782642\n",
      "Episode 402: Total Reward = -59.68148593257311, Average Loss = 9.8430, Epsilon: 0.13264825480308728\n",
      "Episode 403: Total Reward = -26.934356902334756, Average Loss = 8.8001, Epsilon: 0.13198501352907185\n",
      "Episode 404: Total Reward = -33.649834590495004, Average Loss = 8.4370, Epsilon: 0.1313250884614265\n",
      "Episode 405: Total Reward = -52.08555059890639, Average Loss = 9.5933, Epsilon: 0.13066846301911936\n",
      "Episode 406: Total Reward = -55.78069202315483, Average Loss = 9.7795, Epsilon: 0.13001512070402377\n",
      "Episode 407: Total Reward = -9.409826137608619, Average Loss = 10.9822, Epsilon: 0.12936504510050365\n",
      "Episode 408: Total Reward = -61.69925972992385, Average Loss = 7.0369, Epsilon: 0.12871821987500112\n",
      "Episode 409: Total Reward = -50.57887229171223, Average Loss = 6.6459, Epsilon: 0.12807462877562611\n",
      "Episode 410: Total Reward = -52.65812284105431, Average Loss = 9.2219, Epsilon: 0.12743425563174798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 411: Total Reward = -45.09221794918759, Average Loss = 7.2839, Epsilon: 0.12679708435358925\n",
      "Episode 412: Total Reward = -61.16418968214671, Average Loss = 7.1989, Epsilon: 0.1261630989318213\n",
      "Episode 413: Total Reward = -36.66600438278485, Average Loss = 7.5707, Epsilon: 0.1255322834371622\n",
      "Episode 414: Total Reward = -45.82783217901107, Average Loss = 7.9669, Epsilon: 0.12490462201997637\n",
      "Episode 415: Total Reward = -48.788654265195106, Average Loss = 6.3500, Epsilon: 0.1242800989098765\n",
      "Episode 416: Total Reward = -60.65436167026924, Average Loss = 6.8525, Epsilon: 0.12365869841532712\n",
      "Episode 417: Total Reward = -96.54502541676966, Average Loss = 7.9346, Epsilon: 0.12304040492325048\n",
      "Episode 418: Total Reward = -40.25914535685565, Average Loss = 7.5574, Epsilon: 0.12242520289863423\n",
      "Episode 419: Total Reward = -71.03363221479108, Average Loss = 9.7216, Epsilon: 0.12181307688414106\n",
      "Episode 420: Total Reward = -45.56923575768813, Average Loss = 7.7656, Epsilon: 0.12120401149972035\n",
      "Episode 421: Total Reward = -45.95407706172518, Average Loss = 4.8511, Epsilon: 0.12059799144222175\n",
      "Episode 422: Total Reward = -46.843551279934815, Average Loss = 6.5083, Epsilon: 0.11999500148501063\n",
      "Episode 423: Total Reward = -53.6833026866324, Average Loss = 7.0950, Epsilon: 0.11939502647758558\n",
      "Episode 424: Total Reward = -13.597210368400667, Average Loss = 5.5660, Epsilon: 0.11879805134519765\n",
      "Episode 425: Total Reward = -90.33643018557633, Average Loss = 5.5173, Epsilon: 0.11820406108847166\n",
      "Episode 426: Total Reward = -16.86723680655247, Average Loss = 5.2489, Epsilon: 0.1176130407830293\n",
      "Episode 427: Total Reward = -32.45461137074838, Average Loss = 6.4591, Epsilon: 0.11702497557911415\n",
      "Episode 428: Total Reward = -38.893637771564556, Average Loss = 6.5048, Epsilon: 0.11643985070121858\n",
      "Episode 429: Total Reward = -60.41645377780035, Average Loss = 4.9719, Epsilon: 0.11585765144771248\n",
      "Episode 430: Total Reward = -43.52202952897892, Average Loss = 5.3852, Epsilon: 0.11527836319047392\n",
      "Episode 431: Total Reward = -50.44880075549286, Average Loss = 5.5167, Epsilon: 0.11470197137452155\n",
      "Episode 432: Total Reward = -45.56213814556635, Average Loss = 4.6443, Epsilon: 0.11412846151764894\n",
      "Episode 433: Total Reward = -41.92331238355759, Average Loss = 4.5022, Epsilon: 0.1135578192100607\n",
      "Episode 434: Total Reward = -46.58021562583646, Average Loss = 5.7292, Epsilon: 0.11299003011401039\n",
      "Episode 435: Total Reward = -59.097179499358184, Average Loss = 5.4070, Epsilon: 0.11242507996344034\n",
      "Episode 436: Total Reward = -85.87790646341087, Average Loss = 3.9835, Epsilon: 0.11186295456362313\n",
      "Episode 437: Total Reward = -42.24883847990824, Average Loss = 3.6139, Epsilon: 0.11130363979080501\n",
      "Episode 438: Total Reward = 21.44602963007476, Average Loss = 3.4865, Epsilon: 0.11074712159185099\n",
      "Episode 439: Total Reward = -74.88921293592855, Average Loss = 3.5849, Epsilon: 0.11019338598389174\n",
      "Episode 440: Total Reward = -47.00961882053436, Average Loss = 3.2301, Epsilon: 0.10964241905397228\n",
      "Episode 441: Total Reward = -33.81183410141476, Average Loss = 2.9102, Epsilon: 0.10909420695870241\n",
      "Episode 442: Total Reward = -34.406460472410345, Average Loss = 3.4522, Epsilon: 0.1085487359239089\n",
      "Episode 443: Total Reward = -162.87983727414087, Average Loss = 3.2040, Epsilon: 0.10800599224428936\n",
      "Episode 444: Total Reward = -46.06907617353281, Average Loss = 3.0445, Epsilon: 0.10746596228306791\n",
      "Episode 445: Total Reward = -77.71759003558537, Average Loss = 3.1125, Epsilon: 0.10692863247165257\n",
      "Episode 446: Total Reward = 12.770307472091119, Average Loss = 2.8121, Epsilon: 0.1063939893092943\n",
      "Episode 447: Total Reward = -30.89729053400761, Average Loss = 2.3641, Epsilon: 0.10586201936274783\n",
      "Episode 448: Total Reward = -32.44221352159583, Average Loss = 2.7950, Epsilon: 0.10533270926593409\n",
      "Episode 449: Total Reward = -53.295560414633755, Average Loss = 2.7215, Epsilon: 0.10480604571960442\n",
      "Episode 450: Total Reward = -73.3602632315413, Average Loss = 3.0818, Epsilon: 0.1042820154910064\n",
      "Episode 451: Total Reward = -74.925809843065, Average Loss = 2.9859, Epsilon: 0.10376060541355137\n",
      "Episode 452: Total Reward = -24.56189578195874, Average Loss = 2.0433, Epsilon: 0.1032418023864836\n",
      "Episode 453: Total Reward = -0.034656977510508113, Average Loss = 2.5813, Epsilon: 0.10272559337455119\n",
      "Episode 454: Total Reward = -16.40795282311153, Average Loss = 2.7059, Epsilon: 0.10221196540767843\n",
      "Episode 455: Total Reward = -5.666713563899691, Average Loss = 2.5285, Epsilon: 0.10170090558064004\n",
      "Episode 456: Total Reward = -69.7253738218341, Average Loss = 2.4002, Epsilon: 0.10119240105273684\n",
      "Episode 457: Total Reward = -9.528860682493544, Average Loss = 2.4706, Epsilon: 0.10068643904747315\n",
      "Episode 458: Total Reward = -24.276246518411156, Average Loss = 2.8268, Epsilon: 0.10018300685223579\n",
      "Episode 459: Total Reward = -47.980472894162006, Average Loss = 2.6301, Epsilon: 0.0996820918179746\n",
      "Episode 460: Total Reward = -320.6021446555275, Average Loss = 2.9524, Epsilon: 0.0996820918179746\n",
      "Episode 461: Total Reward = -73.8574502017794, Average Loss = 2.4627, Epsilon: 0.0996820918179746\n",
      "Episode 462: Total Reward = -8.569659414965116, Average Loss = 2.0368, Epsilon: 0.0996820918179746\n",
      "Episode 463: Total Reward = -114.26289864072402, Average Loss = 3.1628, Epsilon: 0.0996820918179746\n",
      "Episode 464: Total Reward = -44.18593555125709, Average Loss = 2.8746, Epsilon: 0.0996820918179746\n",
      "Episode 465: Total Reward = -203.6597834640802, Average Loss = 3.9563, Epsilon: 0.0996820918179746\n",
      "Episode 466: Total Reward = 22.65057551909608, Average Loss = 3.4100, Epsilon: 0.0996820918179746\n",
      "Episode 467: Total Reward = -62.029251459946416, Average Loss = 3.3221, Epsilon: 0.0996820918179746\n",
      "Episode 468: Total Reward = 10.755768391765159, Average Loss = 3.2415, Epsilon: 0.0996820918179746\n",
      "Episode 469: Total Reward = 4.4579178732787454, Average Loss = 2.9570, Epsilon: 0.0996820918179746\n",
      "Episode 470: Total Reward = -105.57962392160276, Average Loss = 3.3228, Epsilon: 0.0996820918179746\n",
      "Episode 471: Total Reward = -63.11812099047574, Average Loss = 2.9100, Epsilon: 0.0996820918179746\n",
      "Episode 472: Total Reward = -14.521084623625995, Average Loss = 3.1198, Epsilon: 0.0996820918179746\n",
      "Episode 473: Total Reward = -23.57952753713792, Average Loss = 3.8140, Epsilon: 0.0996820918179746\n",
      "Episode 474: Total Reward = 17.323856126850572, Average Loss = 3.0091, Epsilon: 0.0996820918179746\n",
      "Episode 475: Total Reward = -41.15593344173699, Average Loss = 3.8122, Epsilon: 0.0996820918179746\n",
      "Episode 476: Total Reward = -46.428106122226225, Average Loss = 3.5362, Epsilon: 0.0996820918179746\n",
      "Episode 477: Total Reward = -54.52030809487774, Average Loss = 3.6689, Epsilon: 0.0996820918179746\n",
      "Episode 478: Total Reward = -47.56710398636466, Average Loss = 5.0207, Epsilon: 0.0996820918179746\n",
      "Episode 479: Total Reward = -25.41082331045702, Average Loss = 3.4584, Epsilon: 0.0996820918179746\n",
      "Episode 480: Total Reward = -40.90430578281473, Average Loss = 3.8622, Epsilon: 0.0996820918179746\n",
      "Episode 481: Total Reward = -33.98363339914948, Average Loss = 3.7906, Epsilon: 0.0996820918179746\n",
      "Episode 482: Total Reward = -90.83690090085716, Average Loss = 3.9541, Epsilon: 0.0996820918179746\n",
      "Episode 483: Total Reward = -57.76121618252965, Average Loss = 3.9852, Epsilon: 0.0996820918179746\n",
      "Episode 484: Total Reward = -20.645698020578948, Average Loss = 3.1029, Epsilon: 0.0996820918179746\n",
      "Episode 485: Total Reward = 12.023659173744136, Average Loss = 2.8973, Epsilon: 0.0996820918179746\n",
      "Episode 486: Total Reward = -1256.8207633622897, Average Loss = 3.3309, Epsilon: 0.0996820918179746\n",
      "Episode 487: Total Reward = -16.093016911660484, Average Loss = 23.6754, Epsilon: 0.0996820918179746\n",
      "Episode 488: Total Reward = 28.05360360572132, Average Loss = 8.2704, Epsilon: 0.0996820918179746\n",
      "Episode 489: Total Reward = -30.949579215379913, Average Loss = 3.6335, Epsilon: 0.0996820918179746\n",
      "Episode 490: Total Reward = 7.4604557728690395, Average Loss = 9.0160, Epsilon: 0.0996820918179746\n",
      "Episode 491: Total Reward = -44.68972790620806, Average Loss = 8.7773, Epsilon: 0.0996820918179746\n",
      "Episode 492: Total Reward = 4.143974336087041, Average Loss = 3.2344, Epsilon: 0.0996820918179746\n",
      "Episode 493: Total Reward = 34.42652259230999, Average Loss = 3.1994, Epsilon: 0.0996820918179746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 494: Total Reward = -43.59172478417676, Average Loss = 3.1990, Epsilon: 0.0996820918179746\n",
      "Episode 495: Total Reward = -44.1012782148952, Average Loss = 13.4261, Epsilon: 0.0996820918179746\n",
      "Episode 496: Total Reward = -21.439819952032153, Average Loss = 8.0824, Epsilon: 0.0996820918179746\n",
      "Episode 497: Total Reward = -35.576529254463196, Average Loss = 10.9099, Epsilon: 0.0996820918179746\n",
      "Episode 498: Total Reward = -5.994283427876269, Average Loss = 6.2373, Epsilon: 0.0996820918179746\n",
      "Episode 499: Total Reward = -21.048956366842745, Average Loss = 3.6378, Epsilon: 0.0996820918179746\n"
     ]
    }
   ],
   "source": [
    "for episode in range(500):\n",
    "    observation = env.reset()        # Get a new environment \n",
    "    observation = observation[0]     # Get the valid information ( filter the empty element in the tuple)\n",
    "    done = False                    # If landed\n",
    "    total_reward = 0                \n",
    "    step_count = 0                   # Count the step\n",
    "    hover_counter = 0\n",
    "    last_position = None            # track the previous position\n",
    "    total_loss = 0 \n",
    "    \n",
    "    while not done:\n",
    "        if step_count >= max_steps:  # Check for maximum steps\n",
    "            break\n",
    "        \n",
    "        current_position = (observation[0], observation[1])\n",
    "        \n",
    "        if last_position is not None:  # Avoid the lander from hovering too long\n",
    "            distance = np.sqrt((current_position[0] - last_position[0])**2 + (current_position[1] - last_position[1])**2)\n",
    "            if distance < 0.01:  \n",
    "                hover_counter += 1\n",
    "            else:\n",
    "                hover_counter = 0      # Reset the counter if the lander has moved\n",
    "\n",
    "        last_position = current_position\n",
    "        \n",
    "        state_tensor = torch.FloatTensor(observation).unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "        # Epsilon-greedy action\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = env.action_space.sample()                       # Which action the lander takes, 0,1,2,3\n",
    "        else:\n",
    "            with torch.no_grad():                                    # disable the gradient tracking  \n",
    "                action = policy_net(state_tensor).max(1)[1].item()   # get the best action \n",
    "\n",
    "        next_observation, reward, done, truncated, info = env.step(action)\n",
    "        \n",
    "        if hover_counter >= 90:  # If the lander hovers for 40 steps\n",
    "            reward -= 5         # Apply a penalty of 10 to the reward\n",
    "\n",
    "        # Store transition\n",
    "        replay_memory.append((observation, action, reward, next_observation, done))\n",
    "        if len(replay_memory) > 5000:\n",
    "            replay_memory.pop(0)\n",
    "\n",
    "        # Sample mini-batch and update policy_net\n",
    "        if len(replay_memory) >= batch_size:                  # When the length of buffer greater than the batch size\n",
    "            batch = random.sample(replay_memory, batch_size)\n",
    "            batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones = zip(*batch)\n",
    "\n",
    "            batch_states = torch.FloatTensor(batch_states).to(\"cuda\")\n",
    "            batch_actions = torch.LongTensor(batch_actions).to(\"cuda\")\n",
    "            batch_rewards = torch.FloatTensor(batch_rewards).to(\"cuda\")\n",
    "            batch_next_states = torch.FloatTensor(batch_next_states).to(\"cuda\")\n",
    "            batch_dones = torch.FloatTensor(batch_dones).to(\"cuda\")\n",
    "            \n",
    "            # The TD algo\n",
    "            current_q_values = policy_net(batch_states).gather(1, batch_actions.unsqueeze(1)).squeeze()\n",
    "            next_state_actions = policy_net(batch_next_states).max(1)[1]\n",
    "            next_q_values = target_net(batch_next_states).gather(1, next_state_actions.unsqueeze(1)).squeeze()\n",
    "            expected_q_values = batch_rewards + gamma * next_q_values * (1 - batch_dones)\n",
    "\n",
    "            loss = criterion(current_q_values, expected_q_values.detach())\n",
    "            total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            step_count += 1\n",
    "        # Update target network\n",
    "        if episode % 15 == 0:\n",
    "            target_net.load_state_dict(policy_net.state_dict())        # update the weights and bias\n",
    "\n",
    "        observation = next_observation\n",
    "        total_reward += reward\n",
    "        \n",
    "        \n",
    "    # Decay epsilon\n",
    "    if epsilon > 0.1:\n",
    "        epsilon *= 0.995\n",
    "    \n",
    "    average_loss = total_loss / step_count\n",
    "    \n",
    "    print(f\"Episode {episode}: Total Reward = {total_reward}, Average Loss = {average_loss:.4f}, Epsilon: {epsilon}\")\n",
    "\n",
    "env.close()\n",
    "torch.save(policy_net.state_dict(), 'policy_net_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7cc1fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
